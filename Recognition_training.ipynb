{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Recognition_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**CHECK FOR GPU**"
      ],
      "metadata": {
        "id": "6w-JxvaxEX_j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!nvidia-smi"
      ],
      "outputs": [],
      "metadata": {
        "id": "bKa4nDzZ7kJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONNECT TO GOOGLE DRIVE**"
      ],
      "metadata": {
        "id": "6DObzdHFEdhp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ],
      "outputs": [],
      "metadata": {
        "id": "ISmAy2TS7lPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORT THE LIBRARIES**"
      ],
      "metadata": {
        "id": "WdZs2oF1EhhK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "outputs": [],
      "metadata": {
        "id": "FaB3_WPLr3Uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INITIATE DEVICE**"
      ],
      "metadata": {
        "id": "GjY2sk7dI5fv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "KKQm1CM7I8kX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. SQUEEZENET MODEL INITIALIZATION**"
      ],
      "metadata": {
        "id": "uXCGGxf9ERnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# NE KONVERGIRA / OVERFITTING\n",
        "from torchvision.models import squeezenet1_0\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD\n",
        "\n",
        "model = squeezenet1_0(pretrained=True)\n",
        "model.num_classes = 100\n",
        "model.classifier[1] = nn.Conv2d(512, 100, kernel_size=(1, 1), stride=(1, 1))\n",
        "\n",
        "model.train()\n",
        "\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = optimizer = optim.Adam(model.parameters(), lr=1E-5)\n",
        "\n",
        "model.to(device)\n",
        "print(model)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "7U3L_fJK9eWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. RESNET34 MODEL INITIALIZATION**"
      ],
      "metadata": {
        "id": "YYjbwPuR5rhi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# TRAINED\n",
        "\n",
        "from torchvision.models import resnet34\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "model = resnet34(pretrained=True)\n",
        "\n",
        "# number of classes\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, 100)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optimizer = optim.Adam(model.parameters(), lr=1E-4)\n",
        "\n",
        "model.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FEYFNci55u82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. RESNET18 MODEL INITIALIZATION**"
      ],
      "metadata": {
        "id": "bbu0F2F1q0oy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# TRAINED\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "model = resnet18(pretrained=True)\n",
        "\n",
        "# number of classes\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, 100)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "model.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "qTISZKJWq2--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. RESNET50 MODEL INITIALIZATION**"
      ],
      "metadata": {
        "id": "QSKHRxvkKBgz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# TRAINED\n",
        "\n",
        "from torchvision.models import resnet50\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "model = resnet50(pretrained=True)\n",
        "\n",
        "# number of classes\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, 100)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optimizer = optim.Adam(model.parameters(), lr=1E-4)\n",
        "\n",
        "model.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "xKprwTHMKB8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. VGG MODEL INITIALIZATION**"
      ],
      "metadata": {
        "id": "Cl0ZszfCxXGz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# NE KONVERGIRA / OVERFITTING\n",
        "\n",
        "from torchvision.models import vgg16\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "model = vgg16(pretrained=True)\n",
        "\n",
        "# veliko št. nodeov na dense layerju mreže --> overfitting, močne izgube med trainingom --> update to 1024\n",
        "#model.classifier[3] = nn.Linear(4096,4096)\n",
        "model.classifier[4] = nn.Linear(4096,1024)\n",
        "# number of classes \n",
        "model.classifier[6] = nn.Linear(1024,100) \n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1E-5)\n",
        "\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "outputs": [],
      "metadata": {
        "id": "PFRBhnR7xaZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD DATASET**"
      ],
      "metadata": {
        "id": "aETLg7uDENyI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "#train_dir = \"/mydrive/perfectly_detected_ears/train_pytorch/\"\n",
        "#test_dir = \"/mydrive/perfectly_detected_ears/test_pytorch/\"\n",
        "\n",
        "# MY YOLO4 EXTRACTED DATASET\n",
        "train_dir = \"/mydrive/yolov4_ears/train_pytorch/\"\n",
        "test_dir = \"/mydrive/yolov4_ears/test_pytorch/\"\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                       transforms.RandomVerticalFlip(0.4), \n",
        "                                       transforms.RandomHorizontalFlip(0.4), \n",
        "                                       transforms.RandomResizedCrop((224, 224), scale=(0.8, 1.0)),\n",
        "                                       transforms.ColorJitter(brightness=.3, saturation=.2, contrast=.5),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 3)),\n",
        "                                       transforms.Normalize([0.5442, 0.3906, 0.3292], \n",
        "                                                            [0.2593, 0.2215, 0.2166])\n",
        "                                       ])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.5506, 0.3965, 0.3385],\n",
        "                                                           [0.2567, 0.2192, 0.2177])\n",
        "                                      ])\n",
        "\n",
        "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# TO USE IN TRAIN AND TEST TRANSFORMS\n",
        "#mean, std = get_mean_std(trainloader)\n",
        "#print(mean, std)\n",
        "#mean, std = get_mean_std(testloader)\n",
        "#print(mean, std)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "ewpPr-yxEV13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REUPLOAD POTENTIAL HALF-TRAINED MODEL**"
      ],
      "metadata": {
        "id": "ylJAam7yEnIB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_save_name = 'classifier_resnet34_30.pt'\n",
        "PATH = \"/mydrive/\" + model_save_name\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "epoch = checkpoint['epoch']\n",
        "train_losses = checkpoint['train_loss']\n",
        "test_losses = checkpoint['test_loss']\n",
        "model.train()"
      ],
      "outputs": [],
      "metadata": {
        "id": "dfIrCVqnrl-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAIN**"
      ],
      "metadata": {
        "id": "A73V4T1IEtSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epochs = 100\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 10\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "    for inputs, labels in trainloader:\n",
        "        steps += 1\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logps = model(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        ps = torch.exp(logps)\n",
        "        top_p , top_class = ps.topk(1,dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        \n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logps = model(inputs)\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "                    test_loss += batch_loss.item()\n",
        "                    \n",
        "                    ps = torch.exp(logps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "            train_losses.append(running_loss/len(trainloader))\n",
        "            test_losses.append(test_loss/len(testloader))                    \n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "                  f\"Test accuracy: {100 * accuracy/len(testloader):.3f}%\")\n",
        "            running_loss = 0\n",
        "            model.train()\n",
        "            if ((epoch%50 == 0 and epoch != 0) or (epoch == 30)):\n",
        "              model_save_name = 'classifier_resnet34_'+str(epoch)+'.pt'\n",
        "              PATH = \"/mydrive/\" + model_save_name\n",
        "              state = {\n",
        "                  'epoch': epoch,\n",
        "                  'state_dict': model.state_dict(),\n",
        "                  'optimizer': optimizer.state_dict(),\n",
        "                  'train_loss': train_losses,\n",
        "                  'test_loss': test_losses\n",
        "              }\n",
        "              torch.save(state, PATH)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "4YTol8ZKHpZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE THE MODEL**"
      ],
      "metadata": {
        "id": "xaxxruWEEwcc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_save_name = 'classifier_resnet50_50_jitter_crop.pt'\n",
        "PATH = \"/mydrive/\" + model_save_name\n",
        "state = {\n",
        "    'epoch': epoch,\n",
        "    'state_dict': model.state_dict(),\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "    'train_loss': train_losses,\n",
        "    'test_loss': test_losses\n",
        "}\n",
        "torch.save(state, PATH)"
      ],
      "outputs": [],
      "metadata": {
        "id": "kNnxaChUfakF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PLOT LOSS**"
      ],
      "metadata": {
        "id": "pI_nm458E2ie"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(test_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "_PGlSfHdH0hV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST ON VALIDATION DATASET**"
      ],
      "metadata": {
        "id": "QxVlL7DMFE8f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "       inputs, labels = inputs.to(device), labels.to(device)\n",
        "       logps = model(inputs)\n",
        "       _, predicted = torch.max(logps, 1)\n",
        "       total += labels.size(0)\n",
        "       correct += (predicted == labels).sum().item()\n",
        "       \n",
        "print(total)\n",
        "print(correct)\n",
        "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
      ],
      "outputs": [],
      "metadata": {
        "id": "9Lm3Q4nsoCyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CALCULATE MEAN AND STANDARD DEVIATION OF DATASET**"
      ],
      "metadata": {
        "id": "lc0QcqpJMTG7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_mean_std(loader):\n",
        "  channel_sum, channel_squared_sum, num_batches = 0,0,0\n",
        "\n",
        "  for data, _ in loader:\n",
        "    channel_sum += torch.mean(data, dim=[0,2,3])\n",
        "    channel_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
        "    num_batches += 1\n",
        "  \n",
        "  mean = channel_sum/num_batches\n",
        "  std = (channel_squared_sum/num_batches - mean**2)**0.5\n",
        "\n",
        "  return mean, std"
      ],
      "outputs": [],
      "metadata": {
        "id": "6X1ySIP1MSuZ"
      }
    }
  ]
}